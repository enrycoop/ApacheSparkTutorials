package DataFrames;

import java.util.ArrayList;
import java.util.List;

import org.apache.log4j.Level;
import org.apache.log4j.Logger;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.function.Function;

import org.apache.spark.sql.Dataset;
import org.apache.spark.sql.Row;

import org.apache.spark.sql.RowFactory;
import org.apache.spark.sql.SparkSession;
import org.apache.spark.sql.types.DataTypes;
import org.apache.spark.sql.types.StructField;
import org.apache.spark.sql.types.StructType;

/*
 * Questo tipo di acquisizione lo si pu√≤ impiegare anche se non si conosce lo schema
 */
public class DataFrameWithoutScheme {
    public static void main(String[] args) {
        Logger.getLogger("org").setLevel(Level.ERROR);
        Logger.getLogger("akka").setLevel(Level.ERROR);

        SparkSession spark = SparkSession.builder()
                .appName("Dataframe example")
                .master("local[*]")
                .getOrCreate();

        JavaRDD<String> peopleRDD = spark.sparkContext()
                .textFile("people.txt",1)
                .toJavaRDD();

        //schema generated by a string, this schema is encoded in a string
        String schemaString = "name age";

        //generate the schema based on the string of schema
        List<StructField> fields = new ArrayList<>();

        for (String fieldName : schemaString.split(" ")){
            StructField field = DataTypes.createStructField(fieldName, DataTypes.StringType, true);
            fields.add(field);
        }

        StructType schema = DataTypes.createStructType(fields);

        //convert records of the RDD (people) to rows
        JavaRDD<Row> rowRDD = peopleRDD.map( (Function<String, Row>) record -> {
            String[] attributes = record.split(",");
            return RowFactory.create(attributes[0], attributes[1].trim());
                }
        );

        //apply the schema to the RDD
        Dataset<Row> peopleDataFrame = spark.createDataFrame(rowRDD, schema);

        peopleDataFrame.createOrReplaceTempView("people");

        Dataset<Row> results = spark.sql("SELECT name FROM people");

        results.show();

    }
}
